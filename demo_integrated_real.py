#!/usr/bin/env python3
"""
AI Model Validation PoC - Integrated Demo with Real Services
Uses your laptop's camera with real CVAT, Deepchecks, and Ultralytics integrations
"""

import os
import sys
import time
import json
import asyncio
import cv2
from datetime import datetime
from pathlib import Path

# Add src to path for imports
sys.path.append(str(Path(__file__).parent / 'src'))

from services.real_services import (
    RealServiceOrchestrator,
    DemoLogger
)

class RealWebcamCaptureService:
    """Real webcam service using OpenCV"""
    
    def __init__(self, output_dir="demo_data/real_captured", camera_index=0):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.camera_index = camera_index
        self.cap = None
        self.is_active = False
        
    def initialize(self):
        """Initialize camera"""
        DemoLogger.info("Initializing real camera for integrated workflow...")
        self.cap = cv2.VideoCapture(self.camera_index)
        
        if not self.cap.isOpened():
            raise Exception(f"Could not open camera at index {self.camera_index}")
        
        # Set camera properties
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        self.is_active = True
        DemoLogger.success("Camera initialized for real service integration!")
        
        # Get camera info
        width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = self.cap.get(cv2.CAP_PROP_FPS)
        
        DemoLogger.info(f"Camera settings: {width}x{height} @ {fps}fps")
        return True
    
    def capture_frames(self, count=5):
        """Capture real frames from camera for real service processing"""
        if not self.is_active:
            raise Exception("Camera not initialized. Call initialize() first.")
        
        captured_files = []
        
        DemoLogger.info(f"üì∏ Capturing {count} frames for real AI workflow...")
        DemoLogger.info("Position yourself in front of the camera - starting in 3 seconds...")
        time.sleep(3)
        
        for i in range(count):
            DemoLogger.info(f"Capturing frame {i+1}/{count}...")
            
            # Capture frame
            ret, frame = self.cap.read()
            if not ret:
                DemoLogger.error(f"Failed to capture frame {i+1}")
                continue
            
            # Save frame with descriptive naming
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]
            filename = self.output_dir / f"real_ai_frame_{i+1:02d}_{timestamp}.jpg"
            
            cv2.imwrite(str(filename), frame)
            captured_files.append(filename)
            
            DemoLogger.success(f"üì∏ Frame {i+1} captured: {filename.name}")
            
            # Show preview
            cv2.imshow('AI Training Data Capture', frame)
            cv2.waitKey(1500)  # Show for 1.5 seconds
            
            if i < count - 1:  # Don't wait after last frame
                time.sleep(1)
        
        cv2.destroyAllWindows()
        return captured_files
    
    def cleanup(self):
        """Clean up camera resources"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        self.is_active = False
        DemoLogger.info("Camera resources cleaned up")

class IntegratedAIWorkflowDemo:
    """Complete AI workflow with real camera and real services"""
    
    def __init__(self):
        self.base_dir = Path("demo_data")
        self.base_dir.mkdir(exist_ok=True)
        
        # Initialize services
        self.webcam_service = RealWebcamCaptureService()
        self.orchestrator = RealServiceOrchestrator()
    
    async def run_complete_integrated_workflow(self, frame_count=5, project_name="Integrated Real AI Validation"):
        """Run the complete integrated AI workflow"""
        
        workflow_start = datetime.now()
        DemoLogger.info(f"üöÄ Starting integrated AI workflow: {project_name}")
        
        try:
            # Phase 1: Real Camera Data Capture
            DemoLogger.step(1, "Real Camera Data Capture")
            DemoLogger.info("Using your laptop camera to capture training data...")
            
            self.webcam_service.initialize()
            captured_files = self.webcam_service.capture_frames(frame_count)
            
            DemoLogger.success(f"‚úÖ Captured {len(captured_files)} images for AI training")
            
            # Phase 2: Complete Real Services Workflow
            DemoLogger.step(2, "Real AI Services Integration")
            DemoLogger.info("Processing your images through real AI pipeline...")
            
            workflow_results = await self.orchestrator.run_complete_workflow(
                captured_files, 
                project_name
            )
            
            # Phase 3: Results Analysis and Summary
            DemoLogger.step(3, "Workflow Results Analysis")
            self.analyze_and_display_results(captured_files, workflow_results, workflow_start)
            
            return {
                "captured_files": captured_files,
                "workflow_results": workflow_results,
                "duration": (datetime.now() - workflow_start).total_seconds()
            }
            
        except Exception as e:
            DemoLogger.error(f"Integrated workflow failed: {e}")
            raise
        finally:
            self.webcam_service.cleanup()
    
    def analyze_and_display_results(self, captured_files, workflow_results, start_time):
        """Analyze and display comprehensive workflow results"""
        
        duration = (datetime.now() - start_time).total_seconds()
        
        print("\n" + "="*80)
        print("üéâ INTEGRATED AI MODEL VALIDATION COMPLETE!")
        print("="*80)
        
        print(f"\n‚è±Ô∏è  WORKFLOW SUMMARY:")
        print(f"   ‚Ä¢ Total Duration: {duration:.1f} seconds ({duration/60:.1f} minutes)")
        print(f"   ‚Ä¢ Project Name: {workflow_results.get('project_name', 'Unknown')}")
        print(f"   ‚Ä¢ Workflow ID: {workflow_results.get('workflow_id', 'Unknown')}")
        print(f"   ‚Ä¢ Status: {workflow_results.get('status', 'Unknown').upper()}")
        
        print(f"\nüì∏ REAL CAMERA DATA CAPTURE:")
        print(f"   ‚Ä¢ Images Captured: {len(captured_files)}")
        total_size = sum(f.stat().st_size for f in captured_files) / 1024
        print(f"   ‚Ä¢ Total Size: {total_size:.1f} KB")
        print(f"   ‚Ä¢ Average Size: {total_size/len(captured_files):.1f} KB per image")
        
        # Display individual files
        for i, file in enumerate(captured_files, 1):
            size = file.stat().st_size / 1024
            print(f"      üìÑ Frame {i}: {file.name} ({size:.1f} KB)")
        
        results = workflow_results.get("results", {})
        
        # CVAT Integration Results
        if "cvat_project" in results:
            cvat_data = results["cvat_project"]
            print(f"\nüñºÔ∏è  CVAT ANNOTATION INTEGRATION:")
            print(f"   ‚Ä¢ Project ID: {cvat_data.get('id', 'Unknown')}")
            print(f"   ‚Ä¢ Labels Defined: {len(cvat_data.get('labels', []))}")
            print(f"   ‚Ä¢ Status: {cvat_data.get('status', 'Unknown').upper()}")
            
            if "annotations" in results:
                ann_data = results["annotations"]
                print(f"   ‚Ä¢ Total Annotations: {ann_data.get('annotation_count', 0)}")
                print(f"   ‚Ä¢ Annotation File: {Path(str(ann_data.get('annotation_file', ''))).name}")
        
        # Deepchecks Validation Results
        if "validation" in results:
            val_data = results["validation"]
            quality = val_data.get("dataset_quality", {})
            
            print(f"\n‚úÖ DEEPCHECKS DATA VALIDATION:")
            print(f"   ‚Ä¢ Overall Quality Score: {quality.get('overall_score', 0):.1%}")
            print(f"   ‚Ä¢ Image Quality: {quality.get('image_quality', 0):.1%}")
            print(f"   ‚Ä¢ Annotation Quality: {quality.get('annotation_quality', 0):.1%}")
            print(f"   ‚Ä¢ Data Distribution: {quality.get('data_distribution', 0):.1%}")
            
            checks = val_data.get("checks", [])
            passed_checks = sum(1 for check in checks if check.get("status") == "PASSED")
            print(f"   ‚Ä¢ Validation Checks: {passed_checks}/{len(checks)} PASSED")
            
            recommendations = val_data.get("recommendations", [])
            if recommendations:
                print(f"   ‚Ä¢ Key Recommendations:")
                for rec in recommendations[:3]:  # Show top 3
                    print(f"      ‚Ä¢ {rec}")
        
        # Ultralytics Training Results
        if "training" in results:
            train_data = results["training"]
            metrics = train_data.get("final_metrics", {})
            summary = train_data.get("training_summary", {})
            
            print(f"\nüß† YOLO MODEL TRAINING:")
            print(f"   ‚Ä¢ Model Type: {summary.get('model_type', 'Unknown')}")
            print(f"   ‚Ä¢ Epochs Completed: {summary.get('epochs_completed', 0)}")
            print(f"   ‚Ä¢ Training Time: {summary.get('training_time_minutes', 0):.1f} minutes")
            print(f"   ‚Ä¢ Model Size: {summary.get('model_size_mb', 0):.1f} MB")
            print(f"   ‚Ä¢ Parameters: {summary.get('parameters', 0):,}")
            
            print(f"\nüìä MODEL PERFORMANCE METRICS:")
            print(f"   ‚Ä¢ mAP@50: {metrics.get('mAP50', 0):.3f}")
            print(f"   ‚Ä¢ mAP@50-95: {metrics.get('mAP50-95', 0):.3f}")
            print(f"   ‚Ä¢ Precision: {metrics.get('precision', 0):.3f}")
            print(f"   ‚Ä¢ Recall: {metrics.get('recall', 0):.3f}")
            print(f"   ‚Ä¢ F1-Score: {metrics.get('f1_score', 0):.3f}")
        
        # Model Evaluation Results
        if "evaluation" in results:
            eval_data = results["evaluation"]
            eval_metrics = eval_data.get("metrics", {})
            
            print(f"\nüìà MODEL EVALUATION:")
            print(f"   ‚Ä¢ Final mAP@50: {eval_metrics.get('mAP50', 0):.3f}")
            print(f"   ‚Ä¢ Final Precision: {eval_metrics.get('precision', 0):.3f}")
            print(f"   ‚Ä¢ Final Recall: {eval_metrics.get('recall', 0):.3f}")
            
            speed = eval_data.get("inference_speed", {})
            if speed:
                print(f"   ‚Ä¢ Inference Speed: {speed.get('total_ms', 0):.1f}ms per image")
        
        # File Outputs
        print(f"\nüìÅ GENERATED FILES AND OUTPUTS:")
        print(f"   ‚Ä¢ Original Images: demo_data/real_captured/")
        print(f"   ‚Ä¢ CVAT Annotations: demo_data/real_annotations/")
        print(f"   ‚Ä¢ Validation Reports: demo_data/real_validation/")
        print(f"   ‚Ä¢ YOLO Dataset: demo_data/real_models/yolo_dataset/")
        print(f"   ‚Ä¢ Trained Models: demo_data/real_models/")
        
        # Success Assessment
        overall_success = self.assess_workflow_success(workflow_results)
        
        print(f"\nüéØ WORKFLOW ASSESSMENT:")
        print(f"   ‚Ä¢ Overall Success: {'‚úÖ EXCELLENT' if overall_success >= 0.9 else '‚úÖ GOOD' if overall_success >= 0.8 else '‚ö†Ô∏è NEEDS IMPROVEMENT'}")
        print(f"   ‚Ä¢ Success Score: {overall_success:.1%}")
        
        print(f"\nüí° NEXT STEPS:")
        print(f"   ‚Ä¢ Review all generated files in demo_data/ directory")
        print(f"   ‚Ä¢ Examine validation reports for data quality insights")
        print(f"   ‚Ä¢ Test model predictions on new images")
        print(f"   ‚Ä¢ Consider training with more data for production use")
        print(f"   ‚Ä¢ Deploy model for real-world applications")
        
        print(f"\nüöÄ INTEGRATION SUCCESS!")
        print(f"Your real camera data has been processed through the complete")
        print(f"AI model validation pipeline using real industry-standard tools!")
    
    def assess_workflow_success(self, workflow_results):
        """Assess overall workflow success score"""
        
        if workflow_results.get("status") != "completed":
            return 0.5
        
        results = workflow_results.get("results", {})
        scores = []
        
        # Data capture success
        if "annotations" in results:
            scores.append(1.0)  # Successfully captured and annotated
        
        # Validation success
        if "validation" in results:
            val_quality = results["validation"].get("dataset_quality", {})
            overall_score = val_quality.get("overall_score", 0.8)
            scores.append(overall_score)
        
        # Training success
        if "training" in results:
            train_metrics = results["training"].get("final_metrics", {})
            map50 = train_metrics.get("mAP50", 0.8)
            scores.append(map50)
        
        # Evaluation success
        if "evaluation" in results:
            eval_metrics = results["evaluation"].get("metrics", {})
            eval_map50 = eval_metrics.get("mAP50", 0.8)
            scores.append(eval_map50)
        
        return sum(scores) / len(scores) if scores else 0.7

def print_welcome_banner():
    """Print welcome banner for integrated demo"""
    print("="*80)
    print("ü§ñ AI MODEL VALIDATION - INTEGRATED REAL SERVICES DEMO")
    print("="*80)
    print("This demo provides a complete end-to-end AI model validation workflow:")
    print("")
    print("üì∑ REAL CAMERA CAPTURE:")
    print("   ‚Ä¢ Uses your laptop's camera to capture training images")
    print("   ‚Ä¢ Captures high-quality frames for model training")
    print("")
    print("üîó REAL SERVICE INTEGRATIONS:")
    print("   ‚Ä¢ üñºÔ∏è  CVAT: Computer Vision Annotation Tool integration")
    print("   ‚Ä¢ ‚úÖ Deepchecks: Comprehensive data validation and quality assessment")
    print("   ‚Ä¢ üß† Ultralytics YOLO: State-of-the-art object detection training")
    print("")
    print("üéØ COMPLETE WORKFLOW:")
    print("   ‚Ä¢ Data capture ‚Üí Annotation ‚Üí Validation ‚Üí Training ‚Üí Evaluation")
    print("   ‚Ä¢ Real industry-standard tools and frameworks")
    print("   ‚Ä¢ Production-ready AI model validation pipeline")
    print("")
    print("‚ö° ADVANCED FEATURES:")
    print("   ‚Ä¢ Automatic COCO format annotation generation")
    print("   ‚Ä¢ Multi-dimensional data quality assessment")
    print("   ‚Ä¢ YOLO model training with real performance metrics")
    print("   ‚Ä¢ Comprehensive workflow result analysis")
    print("="*80)

async def main():
    """Main demo function"""
    
    print_welcome_banner()
    
    try:
        # Create integrated demo
        demo = IntegratedAIWorkflowDemo()
        
        # Run complete workflow
        DemoLogger.info("üöÄ Starting integrated real services workflow...")
        
        results = await demo.run_complete_integrated_workflow(
            frame_count=5,
            project_name="Laptop Camera Real AI Training"
        )
        
        DemoLogger.success("üéâ Integrated workflow completed successfully!")
        
        return results
        
    except KeyboardInterrupt:
        print("\nüõë Demo interrupted by user")
    except Exception as e:
        DemoLogger.error(f"Demo failed: {e}")
        print(f"\nüí° Troubleshooting tips:")
        print(f"   ‚Ä¢ Make sure camera permissions are granted")
        print(f"   ‚Ä¢ Check that all dependencies are installed")
        print(f"   ‚Ä¢ Ensure sufficient disk space for model training")
        print(f"   ‚Ä¢ Review error logs for specific issues")
        sys.exit(1)

if __name__ == "__main__":
    # Run the async demo
    asyncio.run(main())